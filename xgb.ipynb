{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "import xgboost as xgb\n",
    "\n",
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_nnew.csv', low_memory=False)\n",
    "test = pd.read_csv('test_nnew.csv', low_memory=False)\n",
    "features = [u'Open', u'Promo', u'SchoolHoliday', u'StateHoliday_0',\n",
    "       u'StateHoliday_a', u'DayOfWeek_1', u'DayOfWeek_2', u'DayOfWeek_3',\n",
    "       u'DayOfWeek_4', u'DayOfWeek_5', u'DayOfWeek_6', u'DayOfWeek_7',\n",
    "       u'CompetitionDistance', u'Promo2', 'year', 'Mean_Sales', 'month', 'day',\n",
    "       u'StoreType_a', u'StoreType_b', u'StoreType_c', u'StoreType_d',\n",
    "       u'Assortment_a', u'Assortment_b', u'Assortment_c', u'CompetitionOpen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['year'] = train.Date.apply(lambda x: x.split('-')[0])\n",
    "train['year'] = train['year'].astype(float)\n",
    "train['month'] = train.Date.apply(lambda x: x.split('-')[1])\n",
    "train['month'] = train['month'].astype(float)\n",
    "train['day'] = train.Date.apply(lambda x: x.split('-')[2])\n",
    "train['day'] = train['day'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['year'] = test.Date.apply(lambda x: x.split('-')[0])\n",
    "test['year'] = test['year'].astype(float)\n",
    "test['month'] = test.Date.apply(lambda x: x.split('-')[1])\n",
    "test['month'] = test['month'].astype(float)\n",
    "test['day'] = test.Date.apply(lambda x: x.split('-')[2])\n",
    "test['day'] = test['day'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [u'Open', u'Promo', u'SchoolHoliday', u'StateHoliday_0',\n",
    "       u'StateHoliday_a', u'DayOfWeek_1', u'DayOfWeek_2', u'DayOfWeek_3',\n",
    "       u'DayOfWeek_4', u'DayOfWeek_5', u'DayOfWeek_6', u'DayOfWeek_7',\n",
    "       u'CompetitionDistance', u'Promo2', 'year', 'Mean_Sales', 'month', 'day',\n",
    "       u'StoreType_a', u'StoreType_b', u'StoreType_c', u'StoreType_d',\n",
    "       u'Assortment_a', u'Assortment_b', u'Assortment_c', u'CompetitionOpen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"eta\": 0.1,\n",
    "          \"max_depth\": 8,\n",
    "          \"subsample\": 0.7,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1,\n",
    "          #\"lambda\" : 500\n",
    "          }\n",
    "num_trees = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 30 rounds.\n",
      "[0]\teval-rmspe:0.909892\ttrain-rmspe:0.910680\n",
      "[1]\teval-rmspe:0.909260\ttrain-rmspe:0.910048\n",
      "[2]\teval-rmspe:0.908107\ttrain-rmspe:0.908895\n",
      "[3]\teval-rmspe:0.906195\ttrain-rmspe:0.906982\n",
      "[4]\teval-rmspe:0.903132\ttrain-rmspe:0.903919\n",
      "[5]\teval-rmspe:0.898640\ttrain-rmspe:0.899425\n",
      "[6]\teval-rmspe:0.892244\ttrain-rmspe:0.893025\n",
      "[7]\teval-rmspe:0.883604\ttrain-rmspe:0.884384\n",
      "[8]\teval-rmspe:0.872363\ttrain-rmspe:0.873143\n",
      "[9]\teval-rmspe:0.858052\ttrain-rmspe:0.858835\n",
      "[10]\teval-rmspe:0.840895\ttrain-rmspe:0.841682\n",
      "[11]\teval-rmspe:0.820573\ttrain-rmspe:0.821379\n",
      "[12]\teval-rmspe:0.797274\ttrain-rmspe:0.798120\n",
      "[13]\teval-rmspe:0.771164\ttrain-rmspe:0.772068\n",
      "[14]\teval-rmspe:0.742548\ttrain-rmspe:0.743544\n",
      "[15]\teval-rmspe:0.711831\ttrain-rmspe:0.712942\n",
      "[16]\teval-rmspe:0.679410\ttrain-rmspe:0.680695\n",
      "[17]\teval-rmspe:0.645651\ttrain-rmspe:0.647147\n",
      "[18]\teval-rmspe:0.611278\ttrain-rmspe:0.613060\n",
      "[19]\teval-rmspe:0.576773\ttrain-rmspe:0.578907\n",
      "[20]\teval-rmspe:0.542175\ttrain-rmspe:0.544764\n",
      "[21]\teval-rmspe:0.508136\ttrain-rmspe:0.511272\n",
      "[22]\teval-rmspe:0.475603\ttrain-rmspe:0.479365\n",
      "[23]\teval-rmspe:0.443573\ttrain-rmspe:0.448096\n",
      "[24]\teval-rmspe:0.412922\ttrain-rmspe:0.418316\n",
      "[25]\teval-rmspe:0.383859\ttrain-rmspe:0.390218\n",
      "[26]\teval-rmspe:0.356479\ttrain-rmspe:0.363991\n",
      "[27]\teval-rmspe:0.330934\ttrain-rmspe:0.339739\n",
      "[28]\teval-rmspe:0.307260\ttrain-rmspe:0.317496\n",
      "[29]\teval-rmspe:0.287004\ttrain-rmspe:0.298655\n",
      "[30]\teval-rmspe:0.267058\ttrain-rmspe:0.280375\n",
      "[31]\teval-rmspe:0.248955\ttrain-rmspe:0.264034\n",
      "[32]\teval-rmspe:0.232950\ttrain-rmspe:0.249876\n",
      "[33]\teval-rmspe:0.218526\ttrain-rmspe:0.237379\n",
      "[34]\teval-rmspe:0.205708\ttrain-rmspe:0.226412\n",
      "[35]\teval-rmspe:0.194658\ttrain-rmspe:0.217180\n",
      "[36]\teval-rmspe:0.185034\ttrain-rmspe:0.209600\n",
      "[37]\teval-rmspe:0.177008\ttrain-rmspe:0.203371\n",
      "[38]\teval-rmspe:0.170128\ttrain-rmspe:0.198003\n",
      "[39]\teval-rmspe:0.164283\ttrain-rmspe:0.193682\n",
      "[40]\teval-rmspe:0.159510\ttrain-rmspe:0.190341\n",
      "[41]\teval-rmspe:0.155491\ttrain-rmspe:0.187663\n",
      "[42]\teval-rmspe:0.152029\ttrain-rmspe:0.185519\n",
      "[43]\teval-rmspe:0.149318\ttrain-rmspe:0.183682\n",
      "[44]\teval-rmspe:0.147251\ttrain-rmspe:0.182402\n",
      "[45]\teval-rmspe:0.145656\ttrain-rmspe:0.181520\n",
      "[46]\teval-rmspe:0.144241\ttrain-rmspe:0.180619\n",
      "[47]\teval-rmspe:0.142918\ttrain-rmspe:0.180022\n",
      "[48]\teval-rmspe:0.142017\ttrain-rmspe:0.179681\n",
      "[49]\teval-rmspe:0.141386\ttrain-rmspe:0.179323\n",
      "[50]\teval-rmspe:0.141061\ttrain-rmspe:0.179339\n",
      "[51]\teval-rmspe:0.140650\ttrain-rmspe:0.179174\n",
      "[52]\teval-rmspe:0.140199\ttrain-rmspe:0.179003\n",
      "[53]\teval-rmspe:0.139762\ttrain-rmspe:0.178944\n",
      "[54]\teval-rmspe:0.139745\ttrain-rmspe:0.178980\n",
      "[55]\teval-rmspe:0.139742\ttrain-rmspe:0.178998\n",
      "[56]\teval-rmspe:0.139427\ttrain-rmspe:0.178726\n",
      "[57]\teval-rmspe:0.139292\ttrain-rmspe:0.178596\n",
      "[58]\teval-rmspe:0.138949\ttrain-rmspe:0.178516\n",
      "[59]\teval-rmspe:0.138998\ttrain-rmspe:0.178615\n",
      "[60]\teval-rmspe:0.138828\ttrain-rmspe:0.178758\n",
      "[61]\teval-rmspe:0.138750\ttrain-rmspe:0.178772\n",
      "[62]\teval-rmspe:0.138679\ttrain-rmspe:0.178797\n",
      "[63]\teval-rmspe:0.138476\ttrain-rmspe:0.178626\n",
      "[64]\teval-rmspe:0.138437\ttrain-rmspe:0.178507\n",
      "[65]\teval-rmspe:0.138375\ttrain-rmspe:0.178615\n",
      "[66]\teval-rmspe:0.138328\ttrain-rmspe:0.178520\n",
      "[67]\teval-rmspe:0.138276\ttrain-rmspe:0.178483\n",
      "[68]\teval-rmspe:0.138250\ttrain-rmspe:0.178570\n",
      "[69]\teval-rmspe:0.138221\ttrain-rmspe:0.178519\n",
      "[70]\teval-rmspe:0.138172\ttrain-rmspe:0.178597\n",
      "[71]\teval-rmspe:0.138182\ttrain-rmspe:0.178674\n",
      "[72]\teval-rmspe:0.137856\ttrain-rmspe:0.178458\n",
      "[73]\teval-rmspe:0.137823\ttrain-rmspe:0.178461\n",
      "[74]\teval-rmspe:0.137765\ttrain-rmspe:0.178309\n",
      "[75]\teval-rmspe:0.137330\ttrain-rmspe:0.177795\n",
      "[76]\teval-rmspe:0.137120\ttrain-rmspe:0.177580\n",
      "[77]\teval-rmspe:0.137062\ttrain-rmspe:0.177758\n",
      "[78]\teval-rmspe:0.137015\ttrain-rmspe:0.177675\n",
      "[79]\teval-rmspe:0.137004\ttrain-rmspe:0.177724\n",
      "[80]\teval-rmspe:0.136841\ttrain-rmspe:0.177669\n",
      "[81]\teval-rmspe:0.136753\ttrain-rmspe:0.177548\n",
      "[82]\teval-rmspe:0.136734\ttrain-rmspe:0.177499\n",
      "[83]\teval-rmspe:0.136625\ttrain-rmspe:0.177396\n",
      "[84]\teval-rmspe:0.136577\ttrain-rmspe:0.177377\n",
      "[85]\teval-rmspe:0.136397\ttrain-rmspe:0.177378\n",
      "[86]\teval-rmspe:0.136390\ttrain-rmspe:0.177271\n",
      "[87]\teval-rmspe:0.136155\ttrain-rmspe:0.177022\n",
      "[88]\teval-rmspe:0.136078\ttrain-rmspe:0.176706\n",
      "[89]\teval-rmspe:0.135955\ttrain-rmspe:0.176592\n",
      "[90]\teval-rmspe:0.135760\ttrain-rmspe:0.176270\n",
      "[91]\teval-rmspe:0.135555\ttrain-rmspe:0.176067\n",
      "[92]\teval-rmspe:0.135514\ttrain-rmspe:0.175977\n",
      "[93]\teval-rmspe:0.135473\ttrain-rmspe:0.175964\n",
      "[94]\teval-rmspe:0.135372\ttrain-rmspe:0.175859\n",
      "[95]\teval-rmspe:0.135253\ttrain-rmspe:0.175761\n",
      "[96]\teval-rmspe:0.135123\ttrain-rmspe:0.175674\n",
      "[97]\teval-rmspe:0.135063\ttrain-rmspe:0.175556\n",
      "[98]\teval-rmspe:0.135087\ttrain-rmspe:0.175534\n",
      "[99]\teval-rmspe:0.134985\ttrain-rmspe:0.175190\n",
      "[100]\teval-rmspe:0.134911\ttrain-rmspe:0.175233\n",
      "[101]\teval-rmspe:0.134824\ttrain-rmspe:0.175110\n",
      "[102]\teval-rmspe:0.134827\ttrain-rmspe:0.174992\n",
      "[103]\teval-rmspe:0.134802\ttrain-rmspe:0.174864\n",
      "[104]\teval-rmspe:0.134743\ttrain-rmspe:0.174567\n",
      "[105]\teval-rmspe:0.134627\ttrain-rmspe:0.174569\n",
      "[106]\teval-rmspe:0.134523\ttrain-rmspe:0.174480\n",
      "[107]\teval-rmspe:0.134463\ttrain-rmspe:0.174432\n",
      "[108]\teval-rmspe:0.134327\ttrain-rmspe:0.174319\n",
      "[109]\teval-rmspe:0.134243\ttrain-rmspe:0.174072\n",
      "[110]\teval-rmspe:0.134073\ttrain-rmspe:0.173914\n",
      "[111]\teval-rmspe:0.134048\ttrain-rmspe:0.173849\n",
      "[112]\teval-rmspe:0.133977\ttrain-rmspe:0.173750\n",
      "[113]\teval-rmspe:0.133900\ttrain-rmspe:0.173590\n",
      "[114]\teval-rmspe:0.133880\ttrain-rmspe:0.173520\n",
      "[115]\teval-rmspe:0.133794\ttrain-rmspe:0.173251\n",
      "[116]\teval-rmspe:0.133702\ttrain-rmspe:0.173267\n",
      "[117]\teval-rmspe:0.133640\ttrain-rmspe:0.173189\n",
      "[118]\teval-rmspe:0.133551\ttrain-rmspe:0.173118\n",
      "[119]\teval-rmspe:0.133339\ttrain-rmspe:0.172982\n",
      "[120]\teval-rmspe:0.133124\ttrain-rmspe:0.172620\n",
      "[121]\teval-rmspe:0.132961\ttrain-rmspe:0.172456\n",
      "[122]\teval-rmspe:0.132857\ttrain-rmspe:0.172264\n",
      "[123]\teval-rmspe:0.132799\ttrain-rmspe:0.172220\n",
      "[124]\teval-rmspe:0.132765\ttrain-rmspe:0.172210\n",
      "[125]\teval-rmspe:0.132744\ttrain-rmspe:0.172190\n",
      "[126]\teval-rmspe:0.132711\ttrain-rmspe:0.172116\n",
      "[127]\teval-rmspe:0.132673\ttrain-rmspe:0.172085\n",
      "[128]\teval-rmspe:0.132602\ttrain-rmspe:0.171998\n",
      "[129]\teval-rmspe:0.132588\ttrain-rmspe:0.171964\n",
      "[130]\teval-rmspe:0.132554\ttrain-rmspe:0.171920\n",
      "[131]\teval-rmspe:0.132525\ttrain-rmspe:0.171786\n",
      "[132]\teval-rmspe:0.132506\ttrain-rmspe:0.171700\n",
      "[133]\teval-rmspe:0.132482\ttrain-rmspe:0.171662\n",
      "[134]\teval-rmspe:0.132464\ttrain-rmspe:0.171636\n",
      "[135]\teval-rmspe:0.132398\ttrain-rmspe:0.171587\n",
      "[136]\teval-rmspe:0.132195\ttrain-rmspe:0.171267\n",
      "[137]\teval-rmspe:0.132134\ttrain-rmspe:0.171219\n",
      "[138]\teval-rmspe:0.132098\ttrain-rmspe:0.171212\n",
      "[139]\teval-rmspe:0.132065\ttrain-rmspe:0.171178\n",
      "[140]\teval-rmspe:0.132003\ttrain-rmspe:0.171108\n",
      "[141]\teval-rmspe:0.132037\ttrain-rmspe:0.170582\n",
      "[142]\teval-rmspe:0.131992\ttrain-rmspe:0.170519\n",
      "[143]\teval-rmspe:0.131937\ttrain-rmspe:0.170566\n",
      "[144]\teval-rmspe:0.131855\ttrain-rmspe:0.170438\n",
      "[145]\teval-rmspe:0.131835\ttrain-rmspe:0.170400\n",
      "[146]\teval-rmspe:0.131758\ttrain-rmspe:0.170387\n",
      "[147]\teval-rmspe:0.131700\ttrain-rmspe:0.170286\n",
      "[148]\teval-rmspe:0.131662\ttrain-rmspe:0.170247\n",
      "[149]\teval-rmspe:0.131598\ttrain-rmspe:0.170223\n",
      "[150]\teval-rmspe:0.131594\ttrain-rmspe:0.170158\n",
      "[151]\teval-rmspe:0.131561\ttrain-rmspe:0.170121\n",
      "[152]\teval-rmspe:0.131533\ttrain-rmspe:0.170091\n",
      "[153]\teval-rmspe:0.131501\ttrain-rmspe:0.170071\n",
      "[154]\teval-rmspe:0.131480\ttrain-rmspe:0.170034\n",
      "[155]\teval-rmspe:0.131368\ttrain-rmspe:0.169846\n",
      "[156]\teval-rmspe:0.131253\ttrain-rmspe:0.169701\n",
      "[157]\teval-rmspe:0.131193\ttrain-rmspe:0.169646\n",
      "[158]\teval-rmspe:0.131203\ttrain-rmspe:0.169627\n",
      "[159]\teval-rmspe:0.131200\ttrain-rmspe:0.169600\n",
      "[160]\teval-rmspe:0.131194\ttrain-rmspe:0.169540\n",
      "[161]\teval-rmspe:0.131031\ttrain-rmspe:0.169437\n",
      "[162]\teval-rmspe:0.131013\ttrain-rmspe:0.169390\n",
      "[163]\teval-rmspe:0.131019\ttrain-rmspe:0.169383\n",
      "[164]\teval-rmspe:0.131003\ttrain-rmspe:0.169337\n",
      "[165]\teval-rmspe:0.131002\ttrain-rmspe:0.169249\n",
      "[166]\teval-rmspe:0.130971\ttrain-rmspe:0.169228\n",
      "[167]\teval-rmspe:0.130888\ttrain-rmspe:0.169156\n",
      "[168]\teval-rmspe:0.130880\ttrain-rmspe:0.169171\n",
      "[169]\teval-rmspe:0.130837\ttrain-rmspe:0.169066\n",
      "[170]\teval-rmspe:0.130797\ttrain-rmspe:0.169033\n",
      "[171]\teval-rmspe:0.130674\ttrain-rmspe:0.168902\n",
      "[172]\teval-rmspe:0.130597\ttrain-rmspe:0.168808\n",
      "[173]\teval-rmspe:0.130557\ttrain-rmspe:0.168798\n",
      "[174]\teval-rmspe:0.130508\ttrain-rmspe:0.167009\n",
      "[175]\teval-rmspe:0.130433\ttrain-rmspe:0.166897\n",
      "[176]\teval-rmspe:0.130384\ttrain-rmspe:0.166825\n",
      "[177]\teval-rmspe:0.130344\ttrain-rmspe:0.166781\n",
      "[178]\teval-rmspe:0.130339\ttrain-rmspe:0.166773\n",
      "[179]\teval-rmspe:0.130326\ttrain-rmspe:0.166751\n",
      "[180]\teval-rmspe:0.130254\ttrain-rmspe:0.166544\n",
      "[181]\teval-rmspe:0.130231\ttrain-rmspe:0.166521\n",
      "[182]\teval-rmspe:0.130202\ttrain-rmspe:0.166514\n",
      "[183]\teval-rmspe:0.130180\ttrain-rmspe:0.166429\n",
      "[184]\teval-rmspe:0.130157\ttrain-rmspe:0.166413\n",
      "[185]\teval-rmspe:0.130128\ttrain-rmspe:0.166347\n",
      "[186]\teval-rmspe:0.130107\ttrain-rmspe:0.165942\n",
      "[187]\teval-rmspe:0.130047\ttrain-rmspe:0.165994\n",
      "[188]\teval-rmspe:0.130043\ttrain-rmspe:0.165909\n",
      "[189]\teval-rmspe:0.130148\ttrain-rmspe:0.165881\n",
      "[190]\teval-rmspe:0.130120\ttrain-rmspe:0.165918\n",
      "[191]\teval-rmspe:0.130150\ttrain-rmspe:0.165888\n",
      "[192]\teval-rmspe:0.130132\ttrain-rmspe:0.165818\n",
      "[193]\teval-rmspe:0.130059\ttrain-rmspe:0.165681\n",
      "[194]\teval-rmspe:0.130034\ttrain-rmspe:0.165622\n",
      "[195]\teval-rmspe:0.129996\ttrain-rmspe:0.165569\n",
      "[196]\teval-rmspe:0.129961\ttrain-rmspe:0.165509\n",
      "[197]\teval-rmspe:0.129952\ttrain-rmspe:0.165521\n",
      "[198]\teval-rmspe:0.129856\ttrain-rmspe:0.165433\n",
      "[199]\teval-rmspe:0.129848\ttrain-rmspe:0.165396\n",
      "[200]\teval-rmspe:0.129814\ttrain-rmspe:0.165354\n",
      "[201]\teval-rmspe:0.129794\ttrain-rmspe:0.165334\n",
      "[202]\teval-rmspe:0.129754\ttrain-rmspe:0.165288\n",
      "[203]\teval-rmspe:0.129737\ttrain-rmspe:0.165264\n",
      "[204]\teval-rmspe:0.129759\ttrain-rmspe:0.165240\n",
      "[205]\teval-rmspe:0.129729\ttrain-rmspe:0.165213\n",
      "[206]\teval-rmspe:0.129715\ttrain-rmspe:0.165236\n",
      "[207]\teval-rmspe:0.129699\ttrain-rmspe:0.165193\n",
      "[208]\teval-rmspe:0.129687\ttrain-rmspe:0.165190\n",
      "[209]\teval-rmspe:0.129675\ttrain-rmspe:0.165165\n",
      "[210]\teval-rmspe:0.129656\ttrain-rmspe:0.165134\n",
      "[211]\teval-rmspe:0.129648\ttrain-rmspe:0.165129\n",
      "[212]\teval-rmspe:0.129607\ttrain-rmspe:0.165091\n",
      "[213]\teval-rmspe:0.129557\ttrain-rmspe:0.164836\n",
      "[214]\teval-rmspe:0.129474\ttrain-rmspe:0.164598\n",
      "[215]\teval-rmspe:0.129418\ttrain-rmspe:0.164589\n",
      "[216]\teval-rmspe:0.129344\ttrain-rmspe:0.164564\n",
      "[217]\teval-rmspe:0.129297\ttrain-rmspe:0.164506\n",
      "[218]\teval-rmspe:0.129279\ttrain-rmspe:0.164480\n",
      "[219]\teval-rmspe:0.129218\ttrain-rmspe:0.164368\n",
      "[220]\teval-rmspe:0.129223\ttrain-rmspe:0.164362\n",
      "[221]\teval-rmspe:0.129225\ttrain-rmspe:0.164357\n",
      "[222]\teval-rmspe:0.129161\ttrain-rmspe:0.164288\n",
      "[223]\teval-rmspe:0.129163\ttrain-rmspe:0.164258\n",
      "[224]\teval-rmspe:0.129052\ttrain-rmspe:0.164206\n",
      "[225]\teval-rmspe:0.129027\ttrain-rmspe:0.164114\n",
      "[226]\teval-rmspe:0.128950\ttrain-rmspe:0.163997\n",
      "[227]\teval-rmspe:0.128926\ttrain-rmspe:0.163978\n",
      "[228]\teval-rmspe:0.128923\ttrain-rmspe:0.163963\n",
      "[229]\teval-rmspe:0.128899\ttrain-rmspe:0.163945\n",
      "[230]\teval-rmspe:0.128864\ttrain-rmspe:0.163928\n",
      "[231]\teval-rmspe:0.128857\ttrain-rmspe:0.163804\n",
      "[232]\teval-rmspe:0.128845\ttrain-rmspe:0.163777\n",
      "[233]\teval-rmspe:0.128822\ttrain-rmspe:0.163751\n",
      "[234]\teval-rmspe:0.128808\ttrain-rmspe:0.163732\n",
      "[235]\teval-rmspe:0.128794\ttrain-rmspe:0.163741\n",
      "[236]\teval-rmspe:0.128782\ttrain-rmspe:0.163710\n",
      "[237]\teval-rmspe:0.128776\ttrain-rmspe:0.163737\n",
      "[238]\teval-rmspe:0.128765\ttrain-rmspe:0.163748\n",
      "[239]\teval-rmspe:0.128758\ttrain-rmspe:0.163743\n",
      "[240]\teval-rmspe:0.128746\ttrain-rmspe:0.163739\n",
      "[241]\teval-rmspe:0.128785\ttrain-rmspe:0.163704\n",
      "[242]\teval-rmspe:0.128778\ttrain-rmspe:0.163681\n",
      "[243]\teval-rmspe:0.128749\ttrain-rmspe:0.163650\n",
      "[244]\teval-rmspe:0.128740\ttrain-rmspe:0.163622\n",
      "[245]\teval-rmspe:0.128735\ttrain-rmspe:0.163607\n",
      "[246]\teval-rmspe:0.128734\ttrain-rmspe:0.163604\n",
      "[247]\teval-rmspe:0.128735\ttrain-rmspe:0.163594\n",
      "[248]\teval-rmspe:0.128729\ttrain-rmspe:0.163572\n",
      "[249]\teval-rmspe:0.128730\ttrain-rmspe:0.163565\n",
      "[250]\teval-rmspe:0.128712\ttrain-rmspe:0.163542\n",
      "[251]\teval-rmspe:0.128654\ttrain-rmspe:0.163458\n",
      "[252]\teval-rmspe:0.128627\ttrain-rmspe:0.163381\n",
      "[253]\teval-rmspe:0.128625\ttrain-rmspe:0.163975\n",
      "[254]\teval-rmspe:0.128622\ttrain-rmspe:0.163966\n",
      "[255]\teval-rmspe:0.128623\ttrain-rmspe:0.163981\n",
      "[256]\teval-rmspe:0.128567\ttrain-rmspe:0.163964\n",
      "[257]\teval-rmspe:0.128569\ttrain-rmspe:0.163957\n",
      "[258]\teval-rmspe:0.128555\ttrain-rmspe:0.163943\n",
      "[259]\teval-rmspe:0.128537\ttrain-rmspe:0.163929\n",
      "[260]\teval-rmspe:0.128523\ttrain-rmspe:0.163915\n",
      "[261]\teval-rmspe:0.128512\ttrain-rmspe:0.163885\n",
      "[262]\teval-rmspe:0.128469\ttrain-rmspe:0.163710\n",
      "[263]\teval-rmspe:0.128463\ttrain-rmspe:0.163666\n",
      "[264]\teval-rmspe:0.128459\ttrain-rmspe:0.163669\n",
      "[265]\teval-rmspe:0.128419\ttrain-rmspe:0.163647\n",
      "[266]\teval-rmspe:0.128420\ttrain-rmspe:0.163625\n",
      "[267]\teval-rmspe:0.128486\ttrain-rmspe:0.163623\n",
      "[268]\teval-rmspe:0.128452\ttrain-rmspe:0.163602\n",
      "[269]\teval-rmspe:0.128437\ttrain-rmspe:0.163570\n",
      "[270]\teval-rmspe:0.128428\ttrain-rmspe:0.163562\n",
      "[271]\teval-rmspe:0.128321\ttrain-rmspe:0.163476\n",
      "[272]\teval-rmspe:0.128310\ttrain-rmspe:0.163469\n",
      "[273]\teval-rmspe:0.128288\ttrain-rmspe:0.163449\n",
      "[274]\teval-rmspe:0.128291\ttrain-rmspe:0.163431\n",
      "[275]\teval-rmspe:0.128169\ttrain-rmspe:0.163342\n",
      "[276]\teval-rmspe:0.128158\ttrain-rmspe:0.163300\n",
      "[277]\teval-rmspe:0.128152\ttrain-rmspe:0.163290\n",
      "[278]\teval-rmspe:0.128125\ttrain-rmspe:0.163256\n",
      "[279]\teval-rmspe:0.128109\ttrain-rmspe:0.163230\n",
      "[280]\teval-rmspe:0.128093\ttrain-rmspe:0.163213\n",
      "[281]\teval-rmspe:0.128072\ttrain-rmspe:0.159621\n",
      "[282]\teval-rmspe:0.128040\ttrain-rmspe:0.159570\n",
      "[283]\teval-rmspe:0.127989\ttrain-rmspe:0.159504\n",
      "[284]\teval-rmspe:0.127893\ttrain-rmspe:0.159418\n",
      "[285]\teval-rmspe:0.127828\ttrain-rmspe:0.159299\n",
      "[286]\teval-rmspe:0.127814\ttrain-rmspe:0.159336\n",
      "[287]\teval-rmspe:0.127797\ttrain-rmspe:0.159343\n",
      "[288]\teval-rmspe:0.127782\ttrain-rmspe:0.159356\n",
      "[289]\teval-rmspe:0.127732\ttrain-rmspe:0.156239\n",
      "[290]\teval-rmspe:0.127714\ttrain-rmspe:0.156215\n",
      "[291]\teval-rmspe:0.127643\ttrain-rmspe:0.156027\n",
      "[292]\teval-rmspe:0.127647\ttrain-rmspe:0.155978\n",
      "[293]\teval-rmspe:0.127602\ttrain-rmspe:0.155891\n",
      "[294]\teval-rmspe:0.127585\ttrain-rmspe:0.155850\n",
      "[295]\teval-rmspe:0.127557\ttrain-rmspe:0.155825\n",
      "[296]\teval-rmspe:0.127568\ttrain-rmspe:0.155768\n",
      "[297]\teval-rmspe:0.127547\ttrain-rmspe:0.155738\n",
      "[298]\teval-rmspe:0.127539\ttrain-rmspe:0.155727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a XGBoost model\n",
      "1017208    2013-01-01\n",
      "Name: Date, dtype: object\n",
      "Validating\n",
      "('error', 0.12750488527963455)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[299]\teval-rmspe:0.127505\ttrain-rmspe:0.155701\n"
     ]
    }
   ],
   "source": [
    "print(\"Train a XGBoost model\")\n",
    "val_size = 100000\n",
    "#train = train.sort(['Date'])\n",
    "print(train.tail(1)['Date'])\n",
    "X_train, X_test = cross_validation.train_test_split(train, test_size=0.05)\n",
    "#X_train, X_test = train.head(len(train) - val_size), train.tail(val_size)\n",
    "dtrain = xgb.DMatrix(X_train[features], np.log(X_train[\"Sales\"] + 1))\n",
    "dvalid = xgb.DMatrix(X_test[features], np.log(X_test[\"Sales\"] + 1))\n",
    "dtest = xgb.DMatrix(test[features])\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, early_stopping_rounds=30, \n",
    "                feval=rmspe_xg)#, verbose_eval=True)\n",
    "\n",
    "print(\"Validating\")\n",
    "train_probs = gbm.predict(xgb.DMatrix(X_test[features]))\n",
    "indices = train_probs < 0\n",
    "train_probs[indices] = 0\n",
    "error = rmspe(np.exp(train_probs) - 1, X_test['Sales'].values)\n",
    "print('error', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make predictions on the test set\n"
     ]
    }
   ],
   "source": [
    "print(\"Make predictions on the test set\")\n",
    "test_probs = gbm.predict(xgb.DMatrix(test[features]))\n",
    "indices = test_probs < 0\n",
    "test_probs[indices] = 0\n",
    "submission = pd.DataFrame({\"Id\": test[\"Id\"], \"Sales\": np.exp(test_probs) - 1})\n",
    "submission.to_csv(\"xgboost_means.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
